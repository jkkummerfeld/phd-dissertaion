\section{Parse Representation}

\begin{figure*}
\begin{subfigure}[b][3.75cm][b]{0.19\textwidth}
  \centering
  \scalebox{0.5}{\input{figures/picture-null-to-null-flat}}
  \caption{\label{fig:null-null}
    Null to null
  }
\end{subfigure}
\hspace{4mm}
\begin{subfigure}[b][3.75cm][b]{0.24\textwidth}
  \centering
  \scalebox{0.5}{ \input{figures/picture-gapping-flat}}
  \caption{\label{fig:gapping}
    Gapping
  }
\end{subfigure}
\hspace{4mm}
\begin{subfigure}[b][3.75cm][b]{0.16\textwidth}
  \centering
  \scalebox{0.5}{ \input{figures/picture-cycle-flat}}
  \caption{\label{fig:cycle}
    Cycle
  }
\end{subfigure}
\hspace{4mm}
\begin{subfigure}[b][3.75cm][b]{0.29\textwidth}
  \centering
  \scalebox{0.5}{ \input{figures/picture-non1ec-flat}}
  \caption{\label{fig:not-1ec}
    Not One-Endpoint Crossing
  }
\end{subfigure}
\caption{
Examples of syntactic phenomena.
Dashed edges are traces, solid edges are structural.
Some edges are fainter to more clearly show the key edges for each case.
}
\end{figure*}

The algorithm we define cannot operate directly on the standard constituent parse representation.
Instead, we define a new representation in which each non-terminal symbol is associated with a specific word (the head).
Unlike dependency parsing, we retain all the information required to reconstruct the constituency parse.

Our representation is based on \textcite{cck}'s tree representation, with three key differences:
(1) we encode all non-terminals explicitly, rather than implicitly through adjunction operations, which can cause ambiguity in the structure,
(2) we add representations of null elements and co-indexation,
(3) we modify the head rules to avoid complex structures.

\subsection{Core Structure}
We represent parses with two components.
Every word is assigned a spine, and every word is the child of one non-trace edge.
Together, these form the base tree structure of the parse.

\parbox{0.44\textwidth}{
\centering
\scalebox{0.7}{
\begin{tikzpicture}
[ every node/.style={
    node distance=2ex,
    inner sep=0pt
  },
  structural/.style={
    ->,
    >=Stealth,
    thin,
  },
  trace/.style={
    ->,
    >=Stealth,
    thin,
    dashed
  },
]

  \node (sntR0) at (0, 1.8) {\strut ROOT};

  \node (snt00) [right=1em of sntR0.east] {\strut NP\textsubscript{SBJ}};
  \node (sw0) [color=black!50,below=-0.3ex of snt00] {\strut Sam};

  \node (snt10) [right=1em of snt00.east] {\strut S};
  \node (snt11) [right=1ex of snt10.east] {\strut VP};
  \draw (snt10.east) -- (snt11.west);
  \node (sw1a) at ($(snt10.west)!0.5!(snt11.east)$) {\strut};
  \node (sw1) [color=black!50,below=-0.3ex of sw1a] {\strut told};

  \node (snt20) [right=1em of snt11.east] {\strut NP};
  \node (sw2) [color=black!50,below=-0.3ex of snt20] {\strut Alex};

  \node (snt30) [right=1.5em of snt20.east] {\strut -};
  \node (sw3) [color=black!50,below=-0.3ex of snt30] {\strut to};

  \node (snt50) [right=1em of snt30.east] {\strut S};
  \node (snt51) [right=1ex of snt50.east] {\strut VP};
  \draw (snt50.east) -- (snt51.west);
  \node (snt52) [right=1ex of snt51.east] {\strut VP};
  \draw (snt51.east) -- (snt52.west);
  \node (sw5a) at ($(snt50.west)!0.5!(snt52.east)$) {\strut};
  \node (sw5) [color=black!50,below=-0.3ex of sw5a] {\strut run};

  \draw [structural,out=60,in=120] (snt00.north) to (snt10.north west);
  \draw [structural,out=120,in=60] (snt10.north) to (sntR0.north);
  \draw [structural,out=120,in=60] (snt20.north) to (snt11.north east);
  \draw [trace,out=30,in=150] (snt20.north) to (snt50.north west);
  \draw [structural,out=120,in=60] (snt50.north) to (snt11.north);
  \draw [structural,out=60,in=120] (snt30.north) to (snt51.north);
\end{tikzpicture}
}}

\paragraph{Spines}
Shown in black immediately above each word, a spine is the ordered set of non-terminals that the word is the head for, \myeg S-NP for \emph{told}.
If a symbol occurs more than once in a spine, we use indices to distinguish between instances.

\paragraph{Edges}
A link between two words, with a label indicating: (1) the top of the child's spine, and (2) the symbol that it connects to in the parent's spine.
In our figures the arcs show their label by starting and ending at the appropriate symbols.

\subsubsection{Avoiding Adjunction Ambiguity}

\textcite{cck} use r-adjunction to add additional non-terminals to spines.
This introduces ambiguity, because edges modifying the same spine from different sides may not have a unique order of application.
We resolve this issue by using more articulated spines that have the complete set of non-terminals.
The potential drawback of our approach is that coverage of spines is more limited by the training set than their approach.
In practice, coverage is high, with $99.93\%$ of spines in the development set observed in the training set.

\subsection{Additional Structure}

The base tree representation described above does not cover null elements or co-indexation, and so only fully represents $26.6\%$ of sentences.

\paragraph{Null Elements}
The Penn Treebank contains a range of null elements, indicating structures such as the trace of movement, PRO, and null complementizers.
These elements do not span any words, so do not have a head word.
For example, in Figure~\ref{fig:repr}a there is a null element that represents the missing subject of the infinitive.

We represent null elements in our structure in two ways.
If the null element has a reference index, shown as a subscript in our figures, we represent the null element as part of an edge, as described below.
Otherwise, we insert it into a spine, as shown for the null element and its parent WHNP in Figure~\ref{fig:null-null}.

\paragraph{Co-indexation}
The treebank represents movement with index pairs on null elements and non-terminals, \myeg *\textsubscript{1} and NP\textsubscript{1} in Figure~\ref{fig:cycle}.
To represent co-indexation we create extra edges, one for each index, going from the null element to the non-terminal.
The edge is labeled to indicate the type of trace and null element.
There are three special cases of co-indexation:

\textbf{(1)}
The treebank uses a chain of indexes to represent the case of a non-terminal that links to multiple null elements.
We represent this case with multiple edges, all starting at the non-terminal and ending at each of the different null positions.

\textbf{(2)}
It is possible for a trace edge to have the same start and end points as a non-trace edge.
We restrict this situation to allow at most one base edge, one trace edge, and one chain edge at the same time.
This decreases edge coverage in the training set by 0.012\%.

\textbf{(3)}
In some cases the non-terminal does not span any words, but instead contains another null element, \myeg the WHNP in Figure~\ref{fig:null-null}.
For these we generate an edge, but reverse the direction.
This reversal is necessary to avoid creating a loop in the structure.
In Figure~\ref{fig:null-null} we show a special case where the trace edge links two positions in the same spine.
We represent this as part of the spine, rather than as an edge.

\paragraph{Gapping}
For parallel constructions the treebank co-indexes arguments that are fulfilling the same roles, as shown in Figure~\ref{fig:gapping}.
These are distinct from the previous cases because neither index is on a null element.
We considered two approaches for these cases: (1) add edges from the repetition to the first occurrence (shown in Figure~\ref{fig:gapping}), (2) add edges from the repetition to the parent of the first occurrence, \myeg the left VP in Figure~\ref{fig:gapping}.
The second approach produces more structures that fall within the graph space we consider and explicitly represents all predicates, but only implicitly captures the original treebank structure.

\subsection{Head Rules}

To construct the spines we use head rules that consider the type of a non-terminal and its children.
In many cases different head word options represent more syntactic or semantic aspects of the span.
When parsing trees, any set of head rules will generate a valid structure.
For graphs, the head rules can have a major impact on properties of the final structure.
Two particular properties that are relevant to our algorithm are whether cycles are present, and whether the edges obey the one-endpoint crossing property.

\paragraph{Cycles}
One example of cycles was mentioned in the previous section, but they can occur whenever a trace edge is added, \myeg between \emph{companies} and \emph{linked} in Figure~\ref{fig:cycle}.
Starting from \textcite{cck}'s head rules, we made modifications to avoid most cycles.
For example, in a subordinate clause consisting of a Wh-noun phrase (WHNP) and a declarative clause (S), we switched the head to be the S.
Often the WHNP has a trace to within the S, so making it the head would create a cycle.

\paragraph{One-Endpoint Crossing}
We generalize \textcite{ec}'s definition of one-endpoint crossing trees to graphs.
A graph is one-endpoint crossing (1ec) if for any edge $e$, all edges that cross $e$ share an endpoint (treating the edges as undirected).

The dark edges in Figure~\ref{fig:not-1ec} show an example of how head rules can impact this property.
The trace edge from \emph{Page} to \emph{CEO of Google} does not satisfy the 1ec property because it is crossed by two edges with no endpoints in common.
By switching the head rule for VPs to use a child VP rather than an auxiliary, we can resolve this case.

\section{Algorithm Extensions}
To handle our representation, we extend the core algorithm described above to support labels on edges and labels on words (spines).
Additionally, we can constrain the search space to structures containing a projective tree of non-trace edges.

\subsection{Edge Labels and Spines}\label{sec:labels}
Edge labels can be added by calculating either the sum or max over edge types when adding each edge, and recording the chosen edge in the back reference for the state.
Spines must be added to the state definition, specifying a label for each visible word ($p$, $q$ and $o$).
This state expansion is necessary to ensure agreement when combining items.
\textcite{cck}'s projective tree parser uses a similar approach, while \textcite{ec}'s algorithm is for dependency parsing and so does not consider spines.

\subsection{Enforcing a tree backbone}
The algorithm above constrains the space of graph structures, but we also want to restrict our search to parses containing a directed projective tree of non-trace edges.
This requirement is satisfied if every word is the child of exactly one non-trace edge, and no non-trace edges cross.

To meet the first condition we add booleans to the state, indicating whether $p$, $q$ and $o$ have non-trace parents.
When adding edges, a non-trace edge cannot be added if the child already has a non-trace parent.
When combining items, no word can receive multiple non-trace parents, and words in the middle of the span must have at least one.

Crossing edges are introduced in two ways:
(1) when adding a $pq$ edge in the $N$, $L$, $R$ and $B$ items, and
(2) when a non-$B$ item is being formed using two non-$I$ items.
In both cases we can avoid non-trace edges crossing by using a boolean that tracks whether there are non-trace $o$--$[pq]$ edges in each item.
The justification is complex and can be found in the supplementary material.

\subsection{Enforcing a tree backbone}
The algorithm above constrains the space of graph structures, but does not say anything about the edge types being combined.
In practice, we are only interested in parses that are composed of trace edges plus a projective tree of structural edges.
Since prior work focused on trees, not graphs, support for this constraint has not previously been explored.

To ensure every point gets one and only one structural parent, we add booleans to the state, indicating whether $p$, $q$ and $o$ have structural parents.
When adding edges, a structural edge can not be added if a point already has a structural parent.
When combining items, no point can receive more than one structural parent, and points in the middle of the span must have at least one.
Together, these constrains ensure we have a tree.

To ensure the tree is projective we need to prevent structural edges from crossing.
Crossing edges are introduced in two ways, and in both we can avoid structural edges crossing by tracking whether there are structural $o$--$[pq]$ edges.

\subsubsection{When creating edges}
Every time we add a $pq$ edge in the $N$, $L$, $R$ and $B$ items we create a crossing with all $o$--$(pq)$ edges.
We do not create a crossing with edges $oq$ or $op$, but our ordering of edge creation means these are definitely not present when we add a $pq$ edge, so tracking structural $o$--$[pq]$ edges gives us the information we need.

We set the boolean for structural $o$--$[pq]$ edges to true if it is currently true or we are creating a structural $op$ or $oq$ edge, and false otherwise.

\subsubsection{When combining items}
In these cases we never introduce a crossing when making a $B$, or in any rule that combines a set of items with only one non-$I$.
That leaves these cases, where the top half and bottom half are symmetrical:

\scalebox{0.9}{
\parbox{\linewidth}{
\begin{flalign*}
  RN\cdotp [ikl \; F \; I\overline{L} \; \overline{IK}] \;\; I[kl \; . \; .] \;\; \cdotp LNX[ljk \; .\overline{K} \; . \; \overline{L}.] \\
  I[il \; F \; .] \;\; \cdotp LN[lki \; .\overline{I} \; .I \; F] \;\; \cdotp \uwave{N}[kjl \; \overline{JL} \; \overline{K}. \; \overline{K}.] \\
  RNX\cdotp [ilk \; F \; .\overline{K} \; I\overline{L}] \;\; I[lk \; . \; .] \;\; \cdotp \uwave{LN}[kjl \; .\overline{L} \; . \; \overline{K}.] \\
  LN[ikx \; .\overline{X} \; .X \; \overline{IK}] \;\; \cdotp N[kji \; \overline{JI} \; \overline{KI} \; \overline{KJ}] \\
  LN[ikx \; .\overline{X} \; .\overline{X} \; \overline{I}K] \;\; \cdotp N[kji \; \overline{JI} \; \overline{KI} \; \overline{KJ}] \\
  X[ikx \; .\overline{X} \; .X \; F] \;\; \cdotp LN[kji \; .\overline{I} \; .\overline{I} \; \overline{KJ}] \\
  X[ikx \; .\overline{X} \; .\overline{X} \; \overline{I}K] \;\; \cdotp LN[kji \; .\overline{I} \; .\overline{I} \; \overline{KJ}] \\[14pt]
  RNX\cdotp [ilk \; \overline{F} \; .\overline{K} \; .\overline{L}] \;\; I[lk \; . \; .] \;\; \cdotp LN[kjl \; J\overline{L} \; F \; \overline{KJ}] \\
  \uwave{N}\cdotp [ikl \; \overline{KF} \; \overline{IL} \; .\overline{K}] \;\; RN\cdotp [klj \; .J \; .\overline{J} \; F] \;\; I[lj \; . \; F] \\
  \uwave{RN}\cdotp [ikl \; \overline{F} \; .\overline{L} \; .\overline{K}] \;\; I[kl \; . \; .] \;\; \cdotp LNX[ljk \; .\overline{K} \; F \; \overline{L}J] \\
  N\cdotp [ikj \; \overline{KJ} \; \overline{IJ} \; \overline{IK}] \;\; RN[kjx \; .X \; .\overline{X} \; \overline{KJ}] \\
  N\cdotp [ikj \; \overline{KJ} \; \overline{IJ} \; \overline{IK}] \;\; RN[kjx \; .\overline{X} \; .\overline{X} \; K\overline{J}] \\
  RN\cdotp [ikj \; .\overline{J} \; .\overline{J} \; \overline{IK}] \;\; X[kjx \; .X \; .\overline{X} \; F] \\
  RN\cdotp [ikj \; .\overline{J} \; .\overline{J} \; \overline{IK}] \;\; X[kjx \; .\overline{X} \; .\overline{X} \; K\overline{J}] \\
\end{flalign*}
}}

While in general there is the potential that an $o$--$[pq]$ boolean might be true because of an $op$ or $oq$ edge that doesn't actually participate in a crossing, the way we have set the parent constraints above means this is not the case.
Instead, all $o$--$[pq]$ edges in each pair of items will cross, and so knowing whether any $o$--$[pq]$ edge is structural is sufficient to determine whether a structural crossing is occurring.
